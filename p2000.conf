# P2000 RSS Feed
#
# Elasticsearch Mapping:
# PUT p2000
# {
#   "mappings": {
#     "items": {
#       "properties": {
#         "location": {
#           "type": "geo_point"
#         }
#       }
#     }
#   }
# }
# 
# Logstash command:
# ./bin/logstash -f p2000.conf

input {
  # Pull every minute
  http_poller {
    urls => {
      	test1 => "http://feeds.livep2000.nl/"
    }
    interval => 60
    codec => "json"
  }
  
}

filter {
  # Only select all the items
  xml {
    source => "message"
    store_xml => "false"
    xpath => ["//item","items"]
  }

  # Remove not used fields
  mutate {
    remove_field => [ "message" ]
    remove_field => [ "tags" ]
  }
  split {
    field => "items"
  }
  # Select the 'event' data from the items
  # doc_id is used in the output section to assign a unique document id
  xml {
    source => "items"
    store_xml => "false"
    xpath => [ 
      "/item/title/text()", "title",
      "/item/description/text()", "description",
      "/item/pubDate/text()", "date",
      "/item/guid/text()", "doc_id",
      "/item/lat/text()", "latitude",
      "/item/long/text()", "longitude"
      ]     
    remove_field => [ "items" ] 
    }
    
  # Parse date
  date {
    match => [ "date", "EEE, dd MMM yyyy HH:mm:ss Z" ]
  }  
  
  # Convert lat/lon to float and assign to location object
  # Only enter this section if location is available
  if [longitude] {
    mutate {
      add_field => {
        "[location][lat]" => "%{latitude}"
        "[location][lon]" => "%{longitude}" 
      }
    }
       
    mutate {
      convert => { "[location][lat]" => "float" }
      convert => { "[location][lon]" => "float" }
    }

    mutate {
      remove_field => [ "latitude", "longitude" ]
    }   
    
  }
  
}

output {
  # Output to Elasticsearch with the unique document id
  elasticsearch { 
  	hosts => ["localhost:9200"]
  	index => "p2000"
  	document_type => "items"
  	document_id => "%{doc_id}"
  }
  
  stdout { codec => rubydebug }
  
}
